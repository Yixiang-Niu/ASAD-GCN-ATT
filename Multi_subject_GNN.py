import os
os.environ["CUDA_VISIBLE_DEVICES"] = "0" # -1强制使用cpu
from tensorflow.python.client import device_lib
device_lib.list_local_devices()    # 查看可用gpu

import tensorflow as tf
import tensorflow_addons as tfa
import numpy as np

# import mne
import eeg_positions

import spektral # √
# import dgl
# import tf2_gnn
# import tensorflow_gnn as tfgnn # √
# import tf_geometric as tfg

# from spikes import encoder

# import keras_spiking
# import spikeflow as sf
# import snntoolbox as snn

from sklearn.model_selection import StratifiedKFold
import h5py
import math

import gc
# %% 自定义子函数
def distances(xyz0, xyz1, r=1, method='Euclidean'):   # 两种方法求测地距离（球面劣弧长）
    '''
        xyz0, xyz1: np array [x, y, z]
        eeg_positions中原点为球心，半径r为单位1
    '''
    # match method:   # python3.10起
    #     case 'geodesic':
    #         # 法一：https://zhuanlan.zhihu.com/p/401891869
    #         length = 2 * r * np.arcsin(
    #             np.sqrt(np.square(xyz0[0]-xyz1[0]) + np.square(xyz0[1]-xyz1[1]) + np.square(xyz0[2]-xyz1[2])) \
    #                 / (2 * r))

    #         # 法二：https://blog.csdn.net/qq_23084801/article/details/77727201
    #         # curve_length = r * np.arccos(
    #         #     (xyz0[0]*xyz1[0] + xyz0[1]*xyz1[1] + xyz0[2]*xyz1[2]) \
    #         #         / np.square(r))
    #     case 'Euclidean':
    #         length = np.linalg.norm(xyz0 - xyz1)

    length = 2 * r * np.arcsin(
        np.sqrt(np.square(xyz0[0]-xyz1[0]) + np.square(xyz0[1]-xyz1[1]) + np.square(xyz0[2]-xyz1[2])) \
            / (2 * r))
    return length
# %% 模型函数
def AAD(shape_eeg, ELE, sources=2, return_attn_coef=False):
    # ------------------------------ 输入 ------------------------------
    inputs = tf.keras.Input(shape=shape_eeg)   # ([batch, num_nodes, time])
    eeg = inputs
    # ----------------------------- GCN ------------------------------
    coordinate = eeg_positions.get_elec_coords(elec_names=ELE, dim='3d')    # 或查阅BioSemi的Cap_coords_all表
    x = np.expand_dims(coordinate['x'].values, axis=-1).astype('float32')
    y = np.expand_dims(coordinate['y'].values, axis=-1).astype('float32')
    z = np.expand_dims(coordinate['z'].values, axis=-1).astype('float32')
    xyz = np.concatenate((x,y,z), axis=-1)  # Cz为(0, 0, 1)

    distance = np.zeros((len(ELE),len(ELE)), dtype='float32')
    for row in range(len(ELE)):
        for col in range(len(ELE)):
            if row == col:
                distance[row,col] = np.inf    # 主对角线置成正无穷，取倒数后为0
            elif col > row:
                # distance[row,col] = distances(xyz[row,:], xyz[col,:], method='geodesic') # geodesic distances
                distance[row,col] = distances(xyz[row,:], xyz[col,:], method='Euclidean')**2    # 之前没取平方，平方后效果更好
            else:
                distance[row,col] = distance[col,row]


    AdjMat = np.reciprocal(distance)    # 取倒数
    AdjMat = (AdjMat - np.min(AdjMat)) / (np.max(AdjMat) - np.min(AdjMat))  # 0-1标准化
    # 还可通过将固定初始化的AdjMat引入loss以对其优化，参见"EEG-Based Emotion Recognition Using Regularized Graph Neural Networks"

    AdjMat = spektral.utils.gcn_filter(AdjMat, symmetric=True)  # 邻接矩阵主对角线加1再规范化
    GCN = spektral.layers.GCNConv(round(eeg.shape[2]), activation='softplus', use_bias=True, kernel_initializer='he_uniform')
    eeg = GCN([eeg, AdjMat])  # 邻接矩阵可0-1也可带权

    # NL = spektral.utils.normalized_laplacian(AdjMat, symmetric=True)
    # RL = spektral.utils.rescale_laplacian(NL, lmax=None)
    # ARMAConv = spektral.layers.ARMAConv(eeg.shape[2], order=3, iterations=2, share_weights=False, gcn_activation='relu', dropout_rate=0.0, activation=None, use_bias=True)
    # eeg = ARMAConv([eeg, RL])

    BN0 = tf.keras.layers.BatchNormalization()
    eeg = BN0(eeg)
    # ----------------------------- GAT ------------------------------
    NumNod = eeg.shape[1]
    AdjMat2 = tf.ones([NumNod, NumNod], tf.float32)  # Spektral的mix mode则忽略以下，否则为batch mode
    AdjMat2 = AdjMat2 - tf.eye(NumNod)  # 主对角线置0
    AdjMat2 = tf.expand_dims(AdjMat2, 0)
    multiples = tf.stack([tf.shape(eeg)[0], tf.constant(1), tf.constant(1)], axis=0)
    AdjMat2 = tf.tile(AdjMat2, multiples)    # batch_size个全1邻接矩阵，dense形式

    GAT = spektral.layers.GATConv(
        round(eeg.shape[2]), attn_heads=3, concat_heads=False, dropout_rate=0, return_attn_coef=return_attn_coef, # 已证实dropout=0更好！
        add_self_loops=True, activation='softplus', use_bias=True, kernel_initializer='he_uniform')    # GAT不需要边权

    if return_attn_coef:
        eeg, attn_coef = GAT([eeg, AdjMat2])    # ([batch, num_nodes, time']), ([batch, num_nodes, attn_heads, num_nodes])
        attn_coef = tf.math.reduce_mean(attn_coef, axis=2, keepdims=False, name='attn_coef')    # 各注意力头平均([batch, num_nodes, num_nodes])；起名不管用，只有keras层能起名
    else:
        eeg = GAT([eeg, AdjMat2])

    BN1 = tf.keras.layers.BatchNormalization()
    eeg = BN1(eeg)
    # -------------------------- ③ Pooling + Readout ---------------------------
    # DiffPool = spektral.layers.DiffPool(round(eeg.shape[1] /4), channels=round(eeg.shape[2] /2),
    #                                     return_selection=False, activation='softplus', kernel_initializer='he_uniform')  # 不支持mix mode；池化到25%节点，节点特征维度缩短到一半
    # eeg, ReAdjMat2 = DiffPool([eeg, AdjMat2])    # DiffPool使用0-1邻接矩阵

    eeg = tf.concat([spektral.layers.GlobalAvgPool()(eeg),
                      spektral.layers.GlobalMaxPool()(eeg)], -1)   # Readout; ([batch, n_node_features])
    # eeg = spektral.layers.GlobalAvgPool()(eeg)

    # BN2 = tf.keras.layers.BatchNormalization()
    # eeg = BN2(eeg)
    # -------------------------- ③ FC ---------------------------
    Dense0 = tf.keras.layers.Dense(math.ceil(eeg.shape[1] /1.5), activation='softplus', kernel_initializer='he_uniform') # 共享标签分类器
    eeg = Dense0(eeg)

    Dense1 = tf.keras.layers.Dense(math.ceil(eeg.shape[1] /2), activation='softplus', kernel_initializer='he_uniform') # 共享标签分类器
    eeg = Dense1(eeg)

    Softmax = tf.keras.layers.Dense(sources, activation='softmax', name='label')    # 起名叫label
    label = Softmax(eeg)   # ([batch, sources])
    # ---------------------------- 构建模型 -----------------------------
    if return_attn_coef:
        model = tf.keras.Model(inputs=inputs, outputs=[label, attn_coef], name='GNNatt')
        # model.compile(loss={'label':'sparse_categorical_crossentropy', 'attn_coef':'mean_squared_error'},
        #               loss_weights={'label':1, 'attn_coef':0},
        #               optimizer=tfa.optimizers.AdamW(learning_rate=1e-3, weight_decay=1e-7, epsilon=1e-3, amsgrad=True),
        #               metrics={'label':'sparse_categorical_accuracy', 'attn_coef':'mean_squared_error'})
        model.compile(loss=['sparse_categorical_crossentropy', 'mean_squared_error'],
                      loss_weights=[1, 0],
                      optimizer=tfa.optimizers.AdamW(learning_rate=1e-3, weight_decay=1e-7, epsilon=1e-3, amsgrad=True),
                      metrics=[['sparse_categorical_accuracy'], ['mean_squared_error']])    # 每个output套一对方括号！
    else:
        model = tf.keras.Model(inputs=inputs, outputs=label, name='GNN')
        model.compile(loss='sparse_categorical_crossentropy',
                      # optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3, epsilon=1e-3, amsgrad=True), # epsilon=1e-3最好，4次之！
                      optimizer=tfa.optimizers.AdamW(learning_rate=1e-3, weight_decay=1e-7, epsilon=1e-3, amsgrad=True),
                      # optimizer=tf.keras.optimizers.Nadam(learning_rate=1e-3, epsilon=1e-3),
                      metrics='sparse_categorical_accuracy')

    model.summary()
    return model
# %% 导入数据
file = r'E:\AAD\My_Research\Datasets\MAD_DE&HOC_2s_0.875_duo_stereo.mat' # ([batch, num_nodes, time])
Mat = h5py.File(file, 'r')

if file.count('duo') == 1:
    sources = 2    # 源的数目！！！！！！！
elif file.count('trio') == 1:
    sources = 3
# ------------------------------------------------
EEG = np.transpose(np.array(Mat['EEG'], dtype='float32'))    # ([batch, num_nodes, time])，加载后反转成([time, num_nodes, batch])
shape_eeg = (EEG.shape[1], EEG.shape[2])

LOC = np.squeeze(np.array(Mat['LOC'], dtype='int8'))    # 未经one-hot的ATT_ori（1和2）用于交叉验证划分等
LOC = LOC-1 # LOC为L1、R2、M3
# 例如一个3分类问题，输出[1,0,0]为第0类，输出[0,1,0]为第1类，输出[0,0,1]为第2类
# ------------------------------------------------
if file.find('MAD') > 0:
    ELE = ['F3','F1','Fz','F2','F4','C3','C1','Cz','C2','C4','CPz','P3','P1','Pz','P2','P4','POz','O1','Oz','O2']
elif file.find('KUL') > 0 or file.find('DTU') > 0:
    ELE = ['Fp1','AF7','AF3','F1','F3','F5','F7','FT7','FC5','FC3','FC1','C1','C3','C5','T7','TP7',
           'CP5','CP3','CP1','P1','P3','P5','P7','P9','PO7','PO3','O1','Iz','Oz','POz','Pz','CPz',
           'Fpz','Fp2','AF8','AF4','AFz','Fz','F2','F4','F6','F8','FT8','FC6','FC4','FC2','FCz','Cz',
           'C2','C4','C6','T8','TP8','CP6','CP4','CP2','P2','P4','P6','P8','P10','PO8','PO4','O2']
# ------------------------------------------------
# channels = 4    # 取注意力前几的通道
# ind_KUL = [1,35,34,2,28,33,42,7,61,43,24,15,8,3,31,57,
#             32,36,52,6,56,19,20,41,58,48,64,49,55,18,21,59,
#             12,63,16,13,62,50,29,9,53,22,60,44,37,5,17,14,
#             54,47,26,30,40,23,46,51,11,10,27,45,25,39,4,38]  # 按下面注意力系数矩阵算出
# EEG = EEG[:, [(x-1) for x in ind_KUL[:channels]], :]
# ele = []
# for i in range(channels):
#     ele.append(ELE[ind_KUL[i]-1])
# ELE = ele
# shape_eeg = (EEG.shape[1], EEG.shape[2])
# ................................................
# EEG = EEG[:,:,:int(np.size(EEG,2)/1.5)] # 只要DE
# EEG = EEG[:,:,int(np.size(EEG,2)/1.5):] # 只要HOC
# shape_eeg = (EEG.shape[1], EEG.shape[2])
# ................................................
# mask = np.zeros(96, dtype=bool)
# mask[32:64] = True # 删除DE某些频段
# EEG = np.delete(EEG, mask, axis=2)
# shape_eeg = (EEG.shape[1], EEG.shape[2])
# ................................................
segments = round(EEG.shape[0] * .8)
# EEG = EEG[:segments,:,:];   LOC = LOC[:segments,]  # 减少数据段
# %% 主函数
skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=None)    # 必须要shuffle！！！random_state随机生成固定的划分
i = 0    # 运行次数
ACC = np.zeros(skf.get_n_splits()).astype('float32')
return_attn_coef = False # 要不要注意力系数
if return_attn_coef:
    attn_coef = np.zeros((skf.get_n_splits(), len(ELE), len(ELE))).astype('float32')
# ------------------------------------------------
for train, test in skf.split(EEG, LOC):
    gc.collect()
    print('★ 以下为第', i+1, '次循环，总共', len(ACC), '次 ★')
    # ..................................................................
    EEG_train, EEG_test = EEG[train,:,:], EEG[test,:,:] # 不能Tensor，必须np数组！！！
    LOC_train, LOC_test = LOC[train], LOC[test]
    # ..................... 生成模型或加载预训练模型 ....................
    model = AAD(shape_eeg, ELE, sources=sources, return_attn_coef=return_attn_coef)
    # ..................................................................
    # tf2ver = tf.__version__[tf.__version__.find('.')+1 :]
    # tf2ver = tf2ver[: tf2ver.find('.')]    # TensorFlow2.tf2ver.*

    if return_attn_coef:
        early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_label_sparse_categorical_accuracy', min_delta=0.0048, patience=7,
                                                          verbose=2, mode='auto', baseline=None, restore_best_weights=True, start_from_epoch=66)    # 必须加label！
        model.fit(EEG_train, [LOC_train, np.zeros((np.size(EEG_train,0),len(ELE),len(ELE))).astype('float32')],
                  batch_size=32, epochs=160, verbose=1, validation_split=1/(skf.get_n_splits()-1), initial_epoch=0, shuffle=True,
                  callbacks = [early_stopping])
    else:
        # early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_sparse_categorical_accuracy', min_delta=0.0048, patience=7,
        #                                                   verbose=2, mode='auto', baseline=None, restore_best_weights=True, start_from_epoch=66)    # TensorFlow2.11
        early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_sparse_categorical_accuracy', min_delta=0.0048, patience=5,
                                                          verbose=2, mode='auto', baseline=None, restore_best_weights=True) # 少通道早停5；少频段77掐掉再给Acc稍微加点
        model.fit(EEG_train, LOC_train,
                  batch_size=32, epochs=160, verbose=1, validation_split=1/(skf.get_n_splits()-1), initial_epoch=0, shuffle=True,
                  callbacks = [early_stopping])
    gc.collect()
    # ..................................................................
    if return_attn_coef:
        LOSS, _, _, ACC[i], _ = model.evaluate(EEG_test, [LOC_test, np.zeros((np.size(EEG_test,0),len(ELE),len(ELE))).astype('float32')])
        _, att = model.predict(EEG_train)
        attn_coef[i,:,:] = np.mean(att, axis=0)
    else:
        LOSS, ACC[i] = model.evaluate(EEG_test, LOC_test)
    # ..................................................................
    # Model.append(model)
    del model    # 此处可删除本轮循环用过不再用的变量
    i = i + 1
# ------------------------------------------------
ACC_mean = np.mean(ACC); ACC_std = np.std(ACC)
# ------------------------------------------------
if return_attn_coef:
    attn_coef = np.mean(attn_coef, axis=0)
''' KUL 2s Euclidean**2
0.0466819	0.0425743	0.0195066	0.00743507	0.00947459	0.0170551	0.0254607	0.0211504	0.010909	0.00864082	0.00848593	0.0118134	0.010511	0.00974887	0.0221562	0.0116007	0.00948209	0.0121438	0.0149709	0.0148054	0.0118206	0.00983525	0.00886163	0.0223361	0.00799995	0.00919341	0.00862113	0.0305419	0.010873	0.00916466	0.0169303	0.0168629	0.0320256	0.044092	0.0446562	0.0181302	0.00989513	0.00758828	0.0077223	0.00914488	0.0159105	0.0255965	0.0249364	0.0101678	0.00807582	0.00892799	0.00936623	0.0132028	0.0128196	0.0102924	0.00876237	0.0188562	0.0108634	0.00927326	0.0121005	0.0153604	0.0164023	0.0142273	0.0119201	0.0102036	0.0245038	0.0113017	0.0118005	0.0142258
0.0468855	0.0427725	0.0196255	0.00732532	0.00945842	0.0173841	0.0256166	0.0211183	0.010788	0.00860692	0.00850473	0.0121782	0.0108102	0.00979238	0.0220801	0.0115174	0.00955328	0.012488	0.0153594	0.0147458	0.0117807	0.00973727	0.00879384	0.022547	0.00789416	0.00897011	0.00849902	0.0306303	0.0107461	0.00893957	0.0168373	0.0171029	0.0319617	0.0441876	0.0447658	0.018146	0.00988264	0.00742982	0.00758878	0.00906218	0.015919	0.0256211	0.024925	0.0100808	0.00796453	0.00879637	0.00930613	0.0133784	0.0128144	0.010244	0.00871248	0.0188609	0.0108504	0.00923424	0.0120597	0.0154949	0.016284	0.0140249	0.0117295	0.0101544	0.0246757	0.0111813	0.0115047	0.0140698
0.0464891	0.0422985	0.0198632	0.00715182	0.00964155	0.0178474	0.0251262	0.0205449	0.0105788	0.00826479	0.00828686	0.0123409	0.0106402	0.00944994	0.0215131	0.0111171	0.00941555	0.0126976	0.0160045	0.0156829	0.0122141	0.0099712	0.00892714	0.0213586	0.007578	0.00901591	0.00821318	0.0293108	0.0105384	0.00893261	0.0182872	0.018248	0.0313217	0.0438448	0.0443679	0.0184988	0.00960204	0.00721673	0.00737562	0.00916959	0.016632	0.0252853	0.024357	0.00979634	0.00760494	0.00873516	0.00932623	0.0139522	0.0133893	0.0102949	0.00830759	0.0182736	0.0104315	0.00918598	0.0126874	0.0166058	0.0178042	0.0151778	0.0123683	0.0102189	0.0237294	0.0108912	0.0120384	0.0139594
0.0458678	0.0418283	0.0197948	0.00667772	0.00956363	0.0180226	0.0248757	0.0200352	0.010185	0.00789584	0.00796929	0.0127864	0.0108281	0.00919996	0.0211122	0.0107085	0.00929171	0.0132419	0.017003	0.0168106	0.0128776	0.0101997	0.00866048	0.0219366	0.00705286	0.00882188	0.00764139	0.0297352	0.0100242	0.00869368	0.0198763	0.01958	0.0301007	0.043331	0.0439823	0.0183414	0.00928448	0.00666498	0.00690367	0.00883294	0.0163665	0.0248597	0.0238552	0.00938295	0.00720791	0.00854357	0.00921775	0.0146211	0.0139968	0.0104389	0.00796134	0.0177842	0.00993416	0.00920469	0.0134946	0.017919	0.0194224	0.0164524	0.0129651	0.00999251	0.0239113	0.0103629	0.0123054	0.0135605
0.0461216	0.0420895	0.0198798	0.00683302	0.00967955	0.0182612	0.0251633	0.0203732	0.0103572	0.00802296	0.00815164	0.0128345	0.0108726	0.00931121	0.0212941	0.0108295	0.00940916	0.0132268	0.016832	0.0164328	0.0126855	0.0101513	0.00880132	0.0213898	0.00723188	0.00883566	0.00780311	0.0290417	0.0101162	0.00867697	0.0193058	0.0191915	0.0304464	0.0434482	0.0441109	0.0184111	0.0094339	0.00680858	0.00701194	0.00892896	0.0164663	0.0250744	0.0240777	0.00950817	0.00731453	0.00858851	0.00928653	0.0145038	0.0138027	0.0103949	0.00807794	0.0179141	0.0100841	0.0092396	0.0132528	0.0175226	0.0188563	0.0159603	0.0126918	0.0100867	0.0234354	0.0104805	0.0119928	0.0135811
0.0462047	0.04224	0.0199015	0.00702958	0.00973488	0.018366	0.0253363	0.0205099	0.0104789	0.00821123	0.00837341	0.0128977	0.0110388	0.0094889	0.0213693	0.0109671	0.00956799	0.0132407	0.0166429	0.0159421	0.0124372	0.0100696	0.00891825	0.0213085	0.00740689	0.00879899	0.00796918	0.0289793	0.0102867	0.00867753	0.0185811	0.0187608	0.0305499	0.0434821	0.0441617	0.0184686	0.00953293	0.00701948	0.00719525	0.00907221	0.0165899	0.0251848	0.0241565	0.00965327	0.00748049	0.00867604	0.00938484	0.0143696	0.0136113	0.0103681	0.00822887	0.0180771	0.0102728	0.00921363	0.0129383	0.017071	0.0180869	0.0153085	0.0123553	0.0101573	0.0234746	0.0106612	0.0117638	0.0136978
0.04689	0.0427774	0.0197235	0.00700142	0.00941775	0.017706	0.0256991	0.0211515	0.0105476	0.00835454	0.00835818	0.0126334	0.0110973	0.0097522	0.0220312	0.011268	0.00955703	0.0129559	0.0160223	0.0151322	0.0119394	0.00964251	0.0086038	0.0227936	0.00757474	0.00863797	0.00812534	0.0306471	0.0103753	0.00861785	0.0174952	0.0178411	0.0317149	0.0441919	0.0447709	0.0182129	0.0098012	0.00702466	0.00723717	0.00886014	0.0159118	0.0255791	0.024784	0.0098381	0.00768647	0.00863609	0.00921598	0.0138485	0.0131778	0.0102873	0.00844356	0.0185874	0.0105133	0.00908735	0.0124486	0.0162683	0.0170161	0.0144351	0.011675	0.00992177	0.0247129	0.0107982	0.0112355	0.0137078
0.0470117	0.0427893	0.0195823	0.0067729	0.00921022	0.0172319	0.0256609	0.021228	0.0104153	0.0081663	0.008159	0.0126149	0.0111281	0.00963258	0.0221745	0.0111965	0.00952744	0.01311	0.016141	0.015325	0.0121357	0.00975711	0.00842816	0.0238588	0.00745764	0.0085489	0.00798675	0.0318301	0.0102278	0.0084895	0.017703	0.017974	0.0319005	0.0443045	0.0449419	0.0179582	0.00980225	0.00675236	0.00701962	0.00857511	0.015475	0.0257082	0.0250529	0.00976478	0.00755785	0.00847226	0.00901593	0.0138185	0.0131965	0.0103051	0.00836364	0.0186175	0.0103158	0.0091259	0.0126637	0.0165032	0.0172834	0.0146057	0.0115629	0.00959404	0.025186	0.0105639	0.011006	0.0135117
0.0464167	0.042298	0.0197309	0.00673303	0.00940313	0.0178513	0.0253369	0.0208203	0.0103807	0.00801148	0.00809231	0.0128096	0.0109935	0.00946609	0.0217918	0.0109766	0.00947036	0.0132894	0.0167135	0.0162003	0.0126492	0.0101539	0.00868224	0.0228214	0.00728051	0.00871215	0.00777223	0.0300786	0.0100179	0.00855494	0.0189102	0.0188383	0.0308564	0.0435931	0.0443383	0.018205	0.00951227	0.00669309	0.00695131	0.00870467	0.0159689	0.0252515	0.0244335	0.00961675	0.00737631	0.00848145	0.00913575	0.0142982	0.0135889	0.0103836	0.00822074	0.0179514	0.00993643	0.0092808	0.0131705	0.0172509	0.0185186	0.0156741	0.012369	0.00980864	0.0239103	0.0103029	0.0115606	0.0133988
0.0460477	0.042004	0.0196831	0.00666838	0.00943557	0.017846	0.0250783	0.0204318	0.0102858	0.00793121	0.00795124	0.0127707	0.0109079	0.00933446	0.0214691	0.0108762	0.00935858	0.0132571	0.0168842	0.0166365	0.0128481	0.0102169	0.00864913	0.0231395	0.00717151	0.00878609	0.00768642	0.0305458	0.00997271	0.00870045	0.0195349	0.0192185	0.0304295	0.0433135	0.0441831	0.0181771	0.00938299	0.00660796	0.00686974	0.00862218	0.015835	0.0250452	0.0242133	0.00949364	0.00729766	0.00847725	0.00911413	0.0144402	0.0137825	0.0104078	0.00811166	0.0178002	0.00983523	0.00923746	0.0133613	0.017588	0.0190948	0.0161674	0.0126281	0.00971264	0.0240663	0.0101577	0.0118234	0.0133953
0.0455738	0.0414814	0.0196568	0.0067474	0.00953458	0.0177955	0.0246524	0.0198748	0.0102467	0.00796753	0.00795664	0.0127811	0.0108991	0.00931837	0.0210372	0.0108324	0.00938741	0.0132953	0.0170239	0.0168854	0.0130093	0.0103754	0.00880005	0.0225743	0.00722105	0.00898408	0.00783186	0.0306513	0.0101616	0.00886944	0.0198641	0.0195334	0.0298182	0.0428995	0.0437627	0.0182025	0.00929969	0.00672559	0.00697073	0.00875989	0.0160226	0.0247007	0.0236468	0.00945261	0.00735525	0.00858673	0.00918521	0.0145718	0.0139789	0.0105173	0.00810686	0.0175757	0.0099815	0.00926732	0.0134743	0.0178525	0.0193248	0.0163328	0.0128626	0.00992447	0.0239479	0.010348	0.0121301	0.0135909
0.0441709	0.0402499	0.0195121	0.00709795	0.0098187	0.0177595	0.0243455	0.019587	0.0105758	0.00828342	0.008217	0.0129057	0.0110666	0.00960969	0.0204698	0.011005	0.00963631	0.0134012	0.0171062	0.0170079	0.013174	0.0106345	0.00915844	0.0222214	0.00765764	0.00934204	0.00828712	0.029958	0.0105125	0.00919582	0.0199668	0.0196153	0.0289658	0.0413458	0.0426375	0.018117	0.00970641	0.00707604	0.00732129	0.00911836	0.016049	0.0242323	0.0229269	0.00984488	0.00775205	0.00887304	0.00942227	0.0146888	0.014106	0.010759	0.00855682	0.0167673	0.0101621	0.00958583	0.0135999	0.0179257	0.0193849	0.0164039	0.0130627	0.010161	0.023083	0.0106577	0.0123174	0.0138399
0.0451739	0.0411973	0.0195117	0.00689055	0.00957096	0.0176348	0.0247588	0.0200909	0.0104641	0.00815756	0.00809733	0.0128414	0.0109876	0.00949072	0.0212276	0.0110421	0.00950344	0.0133322	0.0170267	0.0168715	0.0130571	0.0104667	0.00889072	0.0229113	0.00748325	0.00911013	0.00803708	0.0302324	0.0102631	0.00904993	0.0197893	0.0194583	0.0294571	0.0419666	0.0431264	0.0179645	0.00952964	0.006843	0.00709254	0.00883255	0.0158027	0.0246111	0.0237941	0.00968284	0.00758652	0.00872731	0.00928259	0.0145825	0.0140026	0.0106424	0.0084053	0.0174841	0.00988014	0.00947428	0.0135403	0.0178261	0.0192817	0.0163238	0.0128572	0.00980929	0.0229528	0.0103488	0.0120345	0.0136343
0.0461512	0.0418944	0.0196027	0.00662945	0.00930169	0.0174815	0.0250646	0.0205667	0.0103295	0.00794529	0.00794665	0.0127318	0.0109122	0.00939765	0.0217973	0.0110596	0.00940658	0.0132695	0.0168227	0.0165067	0.0128145	0.0102549	0.00869755	0.0235245	0.0072855	0.00879196	0.00778553	0.0308463	0.0100587	0.00872118	0.0193377	0.0191122	0.0305144	0.0433554	0.0440834	0.0180274	0.00939978	0.00656147	0.00684976	0.00861171	0.0158436	0.025075	0.0242839	0.00959341	0.00736343	0.00848868	0.0090558	0.0143461	0.0137609	0.010438	0.00821481	0.0179703	0.00991168	0.00925182	0.0133412	0.0175586	0.0189332	0.0160093	0.0124327	0.00957608	0.023779	0.010204	0.0116991	0.0134179
0.0468037	0.0425479	0.0195053	0.00671608	0.00919117	0.0169956	0.0254828	0.0211157	0.0103541	0.00807524	0.00801117	0.0124924	0.0110246	0.00953612	0.0221474	0.0111669	0.0095167	0.0131574	0.0161673	0.015454	0.0123229	0.00998747	0.00851868	0.0243825	0.00750269	0.00866059	0.00801308	0.0325427	0.0102635	0.00852515	0.0177457	0.0180748	0.0316647	0.0442066	0.0448815	0.0179578	0.0097294	0.00663395	0.00694614	0.00857589	0.0155546	0.0256975	0.0250364	0.00972123	0.00747466	0.00837969	0.00887463	0.0137738	0.013216	0.0102574	0.00830539	0.0186011	0.0102985	0.00913352	0.0126723	0.0165917	0.0173084	0.014637	0.0116096	0.00957556	0.0255562	0.0105168	0.0110746	0.0135363
0.0464786	0.0421984	0.019516	0.00657228	0.00920745	0.0171064	0.0251553	0.0207099	0.0102442	0.00791014	0.00785016	0.0125184	0.010868	0.00940504	0.021955	0.0111103	0.00944056	0.0132185	0.0165171	0.0160778	0.0126189	0.0101394	0.00867736	0.0242514	0.00733701	0.00869832	0.00786488	0.0321833	0.0101726	0.00859691	0.0186567	0.01866	0.0310745	0.0439387	0.0445435	0.018074	0.00948697	0.00644972	0.00675321	0.00864294	0.0159268	0.0253706	0.0246855	0.0096042	0.00726608	0.00829128	0.00885523	0.0140031	0.0134206	0.0102079	0.00812877	0.0184567	0.0101979	0.00906111	0.0129476	0.0170994	0.0181815	0.0153141	0.0119695	0.00956897	0.0252286	0.0103617	0.011456	0.013517
0.0457803	0.041517	0.0195492	0.006625	0.0093586	0.0174392	0.0246166	0.0200521	0.0102478	0.00794499	0.0079481	0.0127787	0.0109167	0.00937654	0.0214262	0.0110658	0.00945305	0.0133558	0.0170302	0.0168775	0.0130281	0.0104177	0.00887283	0.0230558	0.00729142	0.00896908	0.00785169	0.0302985	0.0101446	0.00887276	0.0198422	0.019442	0.0299291	0.043026	0.0437275	0.0180199	0.00922979	0.00658843	0.00682567	0.00870877	0.0160938	0.0247301	0.0238398	0.00952863	0.00731938	0.00852921	0.00912613	0.0144847	0.0138837	0.0104657	0.00815442	0.0179853	0.010074	0.00927442	0.0134892	0.0178216	0.0193793	0.0163946	0.0128258	0.00984627	0.0233763	0.0103036	0.0120563	0.0135166
0.0446574	0.0406203	0.0194094	0.00702557	0.00971043	0.017525	0.0242723	0.0196276	0.0104774	0.00824172	0.00821443	0.0129265	0.0110803	0.00955414	0.0207482	0.0110496	0.00962625	0.013437	0.01714	0.0170279	0.0131853	0.0106449	0.00911941	0.0223161	0.00762826	0.00933728	0.00824753	0.0295994	0.010412	0.0091821	0.0199894	0.0196106	0.0290738	0.0416089	0.0425388	0.0179568	0.00960016	0.00702003	0.0072593	0.00906933	0.0159767	0.0241615	0.023238	0.00981707	0.00771007	0.00884744	0.00941082	0.0146805	0.0140805	0.0107172	0.00851388	0.0174888	0.0102397	0.0095729	0.0136021	0.0179258	0.0194277	0.0164483	0.0131236	0.0101722	0.0225258	0.0106018	0.0122445	0.0137028
0.0433003	0.0393104	0.0195382	0.00732875	0.0101272	0.0177922	0.0238435	0.0189823	0.0107613	0.00849218	0.00840515	0.0130463	0.0112461	0.00982306	0.0195052	0.0109545	0.00984982	0.0135472	0.0172255	0.017118	0.0132916	0.0108107	0.00944769	0.0217871	0.00789531	0.00953627	0.00852442	0.0292647	0.010603	0.00935682	0.0200936	0.0197323	0.0287983	0.0406733	0.041628	0.0182072	0.0100239	0.007268	0.00753455	0.00943284	0.0161861	0.0238825	0.0225097	0.0101751	0.00798247	0.00903239	0.00957734	0.0148075	0.0142057	0.0108986	0.00881882	0.0166487	0.0105121	0.00978426	0.0136982	0.0180209	0.0195018	0.0165139	0.0132855	0.0104762	0.0225378	0.0108095	0.0124069	0.0136212
0.0442774	0.0396254	0.0197368	0.00717536	0.00999904	0.0176499	0.0233602	0.0184276	0.0105391	0.00835672	0.00834859	0.0130894	0.011253	0.00967009	0.0194501	0.0109011	0.00984606	0.0136613	0.0173553	0.017246	0.0133666	0.0108501	0.00942414	0.0210381	0.00773611	0.00945719	0.00839665	0.029532	0.0106677	0.00925267	0.0202759	0.0198529	0.0288488	0.041525	0.0419619	0.0183908	0.0097263	0.00711978	0.00735346	0.00930223	0.0164707	0.0237646	0.0221772	0.0100237	0.00778077	0.00891138	0.0095155	0.0148291	0.0141725	0.0107841	0.00860363	0.0168208	0.0105454	0.00965318	0.0137046	0.0181048	0.0196851	0.0166255	0.013286	0.0105383	0.0228351	0.0107772	0.0124609	0.0138829
0.0450021	0.0406443	0.0196669	0.00691614	0.00967607	0.0175737	0.0238387	0.0189867	0.0102736	0.00812169	0.0081862	0.0129832	0.0111099	0.0094117	0.0203497	0.0109279	0.00966245	0.0135883	0.0172969	0.0172441	0.0133292	0.0107399	0.00920271	0.0216099	0.00752796	0.00933647	0.00819969	0.0296754	0.0105065	0.00914851	0.020289	0.0197632	0.0289576	0.0421091	0.042803	0.018233	0.00937387	0.00690445	0.00711235	0.00903672	0.0163794	0.0241129	0.0227626	0.00969198	0.00753661	0.00874471	0.00936884	0.0147038	0.0140446	0.0106252	0.00833017	0.0173266	0.0102934	0.00950287	0.0136575	0.0180454	0.0197264	0.0166697	0.0132522	0.0103546	0.0227265	0.0105947	0.0124245	0.0138062
0.0452273	0.0410928	0.0196775	0.0067148	0.00954358	0.0176901	0.0241226	0.0192808	0.0101167	0.00793081	0.00806352	0.0128948	0.0109812	0.00929099	0.0207577	0.0109567	0.00958627	0.013544	0.0172309	0.0172751	0.0133452	0.0106963	0.00910298	0.0221709	0.00736798	0.00924715	0.00802721	0.0298339	0.0103748	0.00904551	0.0203337	0.0196386	0.0290151	0.0424822	0.0431882	0.0181846	0.00914074	0.00671165	0.00690101	0.00887626	0.01646	0.0243903	0.0231521	0.00947044	0.00729121	0.00857827	0.00925848	0.014565	0.0138823	0.0104547	0.00812138	0.0175956	0.0101287	0.00942115	0.0136644	0.0179988	0.0198286	0.0167897	0.0133019	0.0102292	0.0229983	0.0104889	0.0125005	0.0137683
0.0456948	0.0416341	0.0196574	0.00655451	0.0094098	0.0176269	0.0246789	0.0199631	0.0101329	0.00783761	0.00787217	0.0126643	0.0108308	0.00931893	0.0213438	0.0110431	0.00950989	0.0133693	0.0169	0.0168913	0.0130862	0.0104676	0.00894833	0.0235546	0.00726469	0.00895223	0.00783946	0.0310387	0.0101627	0.00880642	0.0198438	0.0191626	0.0298152	0.0431688	0.0438132	0.0181918	0.00921039	0.0064716	0.00668814	0.00868921	0.0163628	0.0248533	0.0238755	0.00943083	0.00709532	0.00830222	0.00899787	0.0142037	0.0135031	0.0102072	0.00800249	0.0179871	0.010077	0.00921115	0.013406	0.0175987	0.0193991	0.016388	0.0128011	0.00984989	0.0243431	0.0103304	0.0121075	0.0135574
0.0468409	0.042592	0.0189402	0.00658075	0.00885277	0.0159301	0.0253644	0.0211401	0.0103034	0.0081204	0.00798458	0.012396	0.0109268	0.00958346	0.022272	0.011281	0.00946067	0.0130747	0.0161346	0.0158652	0.0124994	0.00989942	0.00836308	0.0250435	0.00745058	0.00866105	0.00795203	0.0338521	0.0102072	0.0087534	0.0183035	0.0179045	0.0320367	0.0443046	0.0449132	0.0173988	0.0096945	0.00655746	0.00678748	0.00819856	0.0145761	0.0256994	0.0252863	0.00964766	0.00739881	0.0082559	0.00882531	0.0135129	0.0128307	0.0100726	0.00828706	0.0189775	0.0104522	0.00903046	0.0126954	0.0164446	0.0177822	0.0149546	0.0115884	0.00945876	0.0265336	0.0105342	0.0112035	0.0135266
0.0461322	0.0419082	0.0196335	0.00651187	0.00930878	0.0172746	0.0248323	0.0201702	0.0100851	0.0078049	0.00781251	0.0125366	0.010801	0.00927019	0.021464	0.0110458	0.00937207	0.0132177	0.0166193	0.0167179	0.0128831	0.010199	0.00881263	0.0239826	0.00728549	0.00883004	0.00785334	0.0327008	0.0101595	0.00877742	0.0196742	0.0186298	0.0306437	0.0436672	0.0441933	0.0181962	0.00937886	0.00640719	0.00663114	0.00855879	0.0160755	0.0250827	0.0242621	0.00947049	0.00706136	0.00813515	0.00884447	0.0138112	0.0130312	0.00998115	0.00797055	0.0182169	0.0101678	0.00909194	0.0131723	0.017162	0.01921	0.0161534	0.0124877	0.00970151	0.0252603	0.0103051	0.0118587	0.0135033
0.0454809	0.0412123	0.0197809	0.0066786	0.00945714	0.0175729	0.0241439	0.0191638	0.00998792	0.00785497	0.00801391	0.012776	0.0108984	0.00913312	0.0206195	0.0108313	0.00949758	0.0134546	0.0170234	0.0172247	0.0132945	0.0106453	0.00902079	0.0220147	0.00735874	0.00923769	0.00807225	0.031229	0.010487	0.0090714	0.0203069	0.0192686	0.0293397	0.0429478	0.0435684	0.0184397	0.00920692	0.00666084	0.00683714	0.00881574	0.0164881	0.0244868	0.0230634	0.00948315	0.00719823	0.00841864	0.00913515	0.0142463	0.0134975	0.0102517	0.00802147	0.017616	0.0101602	0.00931486	0.0135085	0.0177066	0.0197902	0.0166997	0.0131984	0.0102029	0.0239013	0.0105914	0.0124896	0.013901
0.0460371	0.0418077	0.0197216	0.00654957	0.00928838	0.0173032	0.0247098	0.0198907	0.0100072	0.00778931	0.00786824	0.0125457	0.0107617	0.00914131	0.0211829	0.0109528	0.00931915	0.0131713	0.0165725	0.0168023	0.0129268	0.0102399	0.00877301	0.0232681	0.00730697	0.00900257	0.0079866	0.0327141	0.010385	0.00894424	0.0198171	0.018563	0.0303478	0.0436117	0.0441568	0.0184168	0.00936734	0.00649158	0.00670143	0.00862976	0.0162146	0.0249637	0.0239136	0.00950423	0.00707925	0.00817646	0.00891322	0.0137936	0.0129554	0.00993144	0.00794361	0.0180389	0.0101761	0.00913008	0.0131955	0.0171459	0.0193671	0.0163213	0.0127411	0.00990543	0.025017	0.0105197	0.012182	0.0137978
0.0470591	0.0426617	0.0190839	0.00664517	0.00877175	0.0154794	0.025343	0.0211945	0.0102941	0.0081162	0.00801375	0.012046	0.0105254	0.00940121	0.0222792	0.0114074	0.0091441	0.0124378	0.0154012	0.0158749	0.0123682	0.0097461	0.00832313	0.0250297	0.00751609	0.00879925	0.00801292	0.0342885	0.0103286	0.00919478	0.0185574	0.0170316	0.0322654	0.0444906	0.045037	0.0176743	0.00990133	0.00671546	0.0069083	0.00827023	0.0145598	0.025689	0.0252135	0.00967707	0.00744752	0.00827027	0.008912	0.0130656	0.012271	0.00976673	0.00829908	0.019005	0.0105685	0.00907891	0.0126959	0.0159468	0.0182439	0.0154966	0.0118782	0.00948217	0.0266675	0.0107316	0.0116702	0.0137247
0.0460583	0.0418324	0.0197936	0.00663871	0.00933749	0.0173914	0.024741	0.0198996	0.0100394	0.00780647	0.00790448	0.0124547	0.0106981	0.00910318	0.0211084	0.0109347	0.00928307	0.013008	0.0162929	0.0166662	0.0128253	0.0102074	0.00869716	0.0227857	0.00729041	0.00905217	0.00803568	0.0328529	0.0104875	0.00904113	0.0196952	0.0182205	0.0302896	0.0436894	0.0442716	0.0185995	0.00942259	0.00660376	0.00683213	0.0087018	0.0162461	0.0250132	0.0238656	0.00955539	0.00711519	0.00819257	0.00893884	0.0136374	0.0127479	0.00985552	0.00799198	0.0180435	0.0102151	0.00918959	0.0131741	0.0169351	0.0193346	0.0163647	0.0128979	0.0100759	0.0250045	0.0106948	0.0123576	0.0139597
0.0456658	0.0412305	0.0197633	0.00670717	0.00944023	0.0173788	0.0241717	0.0192911	0.0100349	0.00790387	0.00800267	0.0127323	0.0109203	0.00919267	0.0206829	0.0108388	0.00945979	0.0133629	0.0168842	0.0170151	0.013119	0.0105068	0.00887402	0.0220103	0.00733146	0.0091554	0.0080672	0.0317508	0.0104891	0.00902024	0.0200687	0.019133	0.0297572	0.0431548	0.0436879	0.0184443	0.00932523	0.00666029	0.00685365	0.00873672	0.0162834	0.0245591	0.0232553	0.00955907	0.00726449	0.00840153	0.00908327	0.0141719	0.0134423	0.0102774	0.00811862	0.0177565	0.0102461	0.00930045	0.013412	0.0175899	0.0195402	0.016455	0.0130156	0.0101803	0.0243324	0.0106589	0.0123488	0.0139223
0.043492	0.0386842	0.0197411	0.00729412	0.0102184	0.0177567	0.0231111	0.0182649	0.0106918	0.00846581	0.00841276	0.0131296	0.0113162	0.0098039	0.0189096	0.010925	0.00994157	0.0136978	0.0173743	0.0172617	0.0133969	0.0109082	0.00953875	0.020812	0.0078203	0.00950495	0.00846731	0.0294944	0.0107502	0.00928968	0.0202857	0.0198756	0.0288088	0.0412593	0.0413374	0.0185222	0.00988119	0.00719145	0.007441	0.00943662	0.0165529	0.0236243	0.0221602	0.0101729	0.00785801	0.00896077	0.00956139	0.0148629	0.0142097	0.0108397	0.00869847	0.0168529	0.0106799	0.0097146	0.0137343	0.0181289	0.0196932	0.0166313	0.0133128	0.0106262	0.0231244	0.0108918	0.0125504	0.0140434
0.0426786	0.0382822	0.0196207	0.00740837	0.0103074	0.017779	0.023394	0.0186318	0.0108549	0.00857345	0.00846295	0.0131026	0.0113207	0.0099435	0.0192602	0.0110756	0.00994388	0.0136121	0.0172784	0.0171576	0.0133298	0.0108566	0.0095592	0.0216481	0.00792986	0.00956119	0.00855415	0.0290797	0.0105734	0.00939372	0.0201452	0.0197828	0.0288636	0.0408019	0.0413845	0.0183472	0.0101277	0.00731055	0.00758024	0.00955781	0.0163547	0.0238406	0.0225816	0.0102912	0.00802068	0.00905814	0.00961088	0.0148463	0.0142332	0.0109311	0.00886531	0.0166589	0.0106792	0.00980795	0.0137223	0.0180591	0.0195529	0.0165516	0.0133182	0.0106082	0.0228151	0.0107579	0.0124661	0.0132938
0.0468503	0.0426592	0.0194003	0.00720009	0.00924549	0.016678	0.025547	0.0212555	0.0107608	0.00842861	0.00823344	0.0116571	0.0103207	0.00954526	0.0222211	0.0115169	0.00922091	0.0120223	0.014997	0.0150005	0.0117962	0.0096448	0.00858064	0.0227363	0.00782692	0.00901458	0.00842532	0.0311841	0.0107316	0.00915796	0.0174226	0.017097	0.0323117	0.0445242	0.0450324	0.0181773	0.00990085	0.00735219	0.00749454	0.00886755	0.0155581	0.0257278	0.0251271	0.0100432	0.00797267	0.00888627	0.00923811	0.0132209	0.0129551	0.0103049	0.00864885	0.0189036	0.0106779	0.00913916	0.0123416	0.0157574	0.0170607	0.014728	0.0118825	0.00985908	0.0247229	0.0111316	0.0119229	0.0141506
0.0464424	0.0424444	0.0193531	0.00735598	0.00937302	0.0169388	0.0254587	0.0210104	0.0107213	0.00843874	0.00826315	0.0115855	0.0102187	0.00945103	0.0220274	0.0115313	0.00918439	0.0119105	0.014824	0.014848	0.0117287	0.00969656	0.00884175	0.0222414	0.00795859	0.00911115	0.00857598	0.030526	0.010856	0.00916031	0.0172512	0.0170111	0.0318255	0.0444959	0.0450002	0.0184321	0.00979922	0.00752105	0.00767747	0.00908753	0.0160626	0.0256331	0.0249089	0.010063	0.00810486	0.0090887	0.00934597	0.0132607	0.0131729	0.0105508	0.00877016	0.0188658	0.010699	0.00931708	0.0125668	0.0158869	0.0169737	0.0147587	0.0120452	0.0100283	0.0243959	0.0112191	0.011888	0.0142152
0.046507	0.0424423	0.0193613	0.0072495	0.00928945	0.0168423	0.0253799	0.021026	0.0106774	0.00843979	0.00825341	0.011726	0.0103902	0.0095143	0.0221237	0.011567	0.00922004	0.0120206	0.0148667	0.0147058	0.0116491	0.00963683	0.00883015	0.0223925	0.00790188	0.00898275	0.00850556	0.0307809	0.010773	0.00903913	0.0170754	0.0169517	0.0318034	0.0444948	0.0450678	0.0183281	0.00977352	0.00740027	0.00759894	0.0090677	0.0162667	0.0257354	0.0251035	0.0100936	0.00810952	0.00909804	0.00930857	0.0132818	0.0132672	0.0106783	0.00882269	0.0189821	0.0107292	0.0093782	0.0126647	0.0159531	0.0168748	0.0146585	0.0119371	0.0099932	0.0245131	0.0111256	0.0116755	0.0140931
0.0461374	0.0420517	0.0196106	0.00706758	0.00941264	0.0174751	0.0250124	0.0204193	0.0104703	0.00817009	0.00814697	0.0121063	0.0104318	0.0092839	0.0214861	0.0111479	0.00919244	0.0124532	0.0157602	0.0156318	0.0120862	0.00979607	0.00886256	0.0212904	0.00754027	0.00894218	0.00818925	0.029375	0.0105666	0.00897065	0.0184051	0.0181901	0.0311155	0.0442991	0.0447176	0.0187406	0.00947033	0.00723744	0.00742249	0.00919266	0.0167378	0.0253323	0.0243494	0.00977675	0.00775145	0.00898014	0.00937977	0.0139295	0.013684	0.0106102	0.00843979	0.0183327	0.0103856	0.00931382	0.0130547	0.0168867	0.0181204	0.0155586	0.0125134	0.0101717	0.0236452	0.0109261	0.0122135	0.014029
0.0466519	0.0423626	0.0197703	0.00672691	0.00928861	0.0173026	0.0251763	0.0205015	0.0102918	0.00791838	0.00794931	0.0124123	0.010603	0.00921768	0.0214646	0.0108784	0.00919243	0.0128159	0.0163849	0.0161933	0.0123921	0.00982571	0.00849947	0.0216844	0.00720231	0.00875733	0.00781782	0.0300558	0.0102045	0.00878258	0.0191237	0.0188585	0.0316488	0.0442721	0.0446561	0.0184898	0.0095959	0.00676879	0.00701598	0.00894419	0.0163964	0.0253653	0.0245325	0.0096003	0.00735471	0.0085788	0.00916137	0.014203	0.0136904	0.0103391	0.00807663	0.0181724	0.0100886	0.00907769	0.0131002	0.0172924	0.0187281	0.0159038	0.012494	0.00985227	0.0239253	0.0105489	0.012115	0.0137044
0.0456378	0.0415053	0.0197745	0.00668031	0.00951369	0.0178452	0.0245431	0.0196023	0.0100729	0.00783904	0.00796464	0.0128404	0.0108529	0.0091471	0.0208317	0.0106561	0.00934501	0.013332	0.0171254	0.0169762	0.0130255	0.0103498	0.0087173	0.0217943	0.00704636	0.00891675	0.00769991	0.030096	0.0101329	0.00876153	0.0200497	0.0197452	0.0297774	0.043165	0.0438411	0.0184158	0.00927336	0.00671372	0.00696171	0.00891889	0.0165182	0.02474	0.0236342	0.00942745	0.00725311	0.00858906	0.00925789	0.0147208	0.0140818	0.0104945	0.00799665	0.0176455	0.00992643	0.00923715	0.0135573	0.0180406	0.0195446	0.0165224	0.0130314	0.00999997	0.0238314	0.0103814	0.0124378	0.0136429
0.0457246	0.0415831	0.0197269	0.00667113	0.00942531	0.017653	0.0246067	0.0197095	0.0101072	0.00782938	0.00796897	0.0128318	0.010841	0.00917709	0.0209704	0.0107306	0.00931622	0.0132913	0.0170613	0.0168267	0.0128976	0.0102195	0.00867086	0.0215179	0.00704587	0.00881888	0.00768942	0.0297919	0.0101405	0.00874282	0.0198651	0.0196543	0.0300377	0.0433444	0.0440337	0.0184375	0.00933008	0.00670401	0.00697029	0.00900057	0.0166639	0.0249332	0.0239934	0.00957271	0.00730789	0.00860317	0.00926299	0.0147044	0.0140777	0.0104968	0.00804987	0.017933	0.0100126	0.00918785	0.0134977	0.0179818	0.0194023	0.0163964	0.0129076	0.00998371	0.023618	0.0104146	0.0123754	0.0136579
0.0458537	0.041762	0.0196892	0.00673343	0.00938992	0.0176077	0.0247952	0.0200726	0.0102205	0.00789551	0.00800576	0.0126471	0.0107233	0.00921316	0.0212255	0.0108797	0.00930737	0.013102	0.0166891	0.0164178	0.0126529	0.0100918	0.00873174	0.0209254	0.00716353	0.00882415	0.00781271	0.0292624	0.0102147	0.00874969	0.0193568	0.0191695	0.0303324	0.0436521	0.0443401	0.0184922	0.00937646	0.00680028	0.00706387	0.00909063	0.016855	0.025218	0.0243423	0.00971133	0.00743557	0.00872341	0.00927839	0.0144603	0.0139902	0.0105931	0.00821935	0.0181857	0.0101317	0.00927801	0.0134239	0.0176967	0.0190423	0.0161915	0.0128412	0.0100834	0.0233989	0.0105637	0.0122697	0.0137325
0.0459302	0.0417806	0.0196702	0.00691906	0.00942414	0.0175477	0.0247919	0.0202878	0.010382	0.00806652	0.00813072	0.0124195	0.0106542	0.00929274	0.0214315	0.0110894	0.00930242	0.0128013	0.0161179	0.0158301	0.0123066	0.00999873	0.00890047	0.0209501	0.00742375	0.00888238	0.00802548	0.0291197	0.010361	0.00881357	0.0186248	0.0184622	0.0305753	0.0438528	0.0445797	0.0185412	0.00942883	0.00703139	0.00729055	0.00919339	0.0170266	0.0254679	0.024554	0.00984256	0.0076569	0.00893525	0.00934089	0.0141274	0.0138996	0.0107569	0.00842418	0.0183472	0.0103142	0.009411	0.0133469	0.017275	0.01841	0.0157574	0.0126393	0.0101905	0.0234397	0.0107359	0.0120684	0.0138002
0.0466044	0.0424022	0.0195016	0.00698423	0.00921905	0.0169239	0.0253488	0.0209708	0.0105223	0.00822443	0.00809969	0.01202	0.010552	0.00941663	0.0220233	0.0113685	0.00919426	0.0123526	0.0153647	0.0149966	0.0117905	0.00967721	0.00870802	0.0224228	0.00769929	0.00876832	0.00825417	0.0308046	0.0105144	0.00878696	0.0175194	0.0174607	0.0317551	0.0444051	0.0450618	0.0182081	0.00976583	0.00707891	0.00734313	0.00900188	0.0165785	0.0258625	0.0252181	0.00999686	0.00788835	0.00893348	0.00916977	0.0135281	0.0134731	0.0107185	0.00864867	0.0188993	0.010565	0.00936213	0.0129095	0.0164543	0.0172922	0.0148606	0.0119435	0.00989661	0.0244669	0.0108719	0.0114989	0.013847
0.0468198	0.0425216	0.0195011	0.00671932	0.00909782	0.0166547	0.025369	0.0209886	0.0103128	0.00800464	0.00786423	0.0120371	0.0106115	0.00932726	0.0220147	0.0111787	0.00919501	0.0125299	0.015551	0.0151528	0.0119125	0.00968585	0.00849267	0.0235807	0.00758777	0.00856069	0.00804517	0.0319624	0.0103021	0.00863381	0.0177627	0.0177289	0.0319535	0.0443635	0.0450153	0.0178009	0.00985842	0.006717	0.0070834	0.00871962	0.0161077	0.02587	0.0253622	0.00992956	0.00770869	0.00864023	0.00888372	0.0135551	0.0134826	0.0106552	0.00847351	0.0189072	0.0104947	0.00937562	0.0130683	0.0167646	0.0175409	0.0150188	0.011906	0.0097378	0.0255669	0.0106751	0.0113931	0.0136639
0.04623	0.0419748	0.0195748	0.00659795	0.00918956	0.0171549	0.0249878	0.0204024	0.0102478	0.00789388	0.00789825	0.0124913	0.0107495	0.00930895	0.0215609	0.0109919	0.00931735	0.0129798	0.016366	0.0160258	0.0124088	0.00996083	0.00866027	0.0222424	0.00725167	0.00864922	0.00775134	0.0303088	0.0100491	0.00865087	0.0189	0.0187345	0.0310203	0.0438691	0.0445811	0.0180964	0.00948706	0.006601	0.00698056	0.00897072	0.0167009	0.0255207	0.0249438	0.00986586	0.00746162	0.00859968	0.00904606	0.0141713	0.013847	0.0106043	0.00830414	0.0185824	0.0102343	0.009304	0.0134319	0.0175278	0.0186912	0.0159145	0.0124501	0.00979075	0.0242498	0.0103837	0.0117904	0.013466
0.0458873	0.0415892	0.0195387	0.0066041	0.00923785	0.017164	0.0246689	0.0200399	0.0102042	0.00787704	0.00789911	0.012719	0.0108559	0.00929092	0.0212497	0.0108759	0.00932702	0.0132221	0.0168587	0.0165525	0.0127481	0.010124	0.00861536	0.0224724	0.0071458	0.00876042	0.00772639	0.0305038	0.0100233	0.00877088	0.0194734	0.0192988	0.0303676	0.0434578	0.044221	0.018159	0.00938571	0.00659801	0.00693854	0.00898815	0.0165657	0.025162	0.0244638	0.00978833	0.00739296	0.00853376	0.00910371	0.0144741	0.0139404	0.0105063	0.00819147	0.0183813	0.0101988	0.00918066	0.0133988	0.0177768	0.0190849	0.0161231	0.0125975	0.0098148	0.0242693	0.0102891	0.0119417	0.01338
0.0455038	0.0410822	0.0196359	0.00677293	0.00945987	0.0174337	0.0242782	0.0195655	0.0101882	0.00794033	0.00798499	0.0128105	0.0109072	0.00928847	0.0208587	0.0108307	0.00941682	0.0133235	0.0170342	0.0168336	0.0129834	0.0103905	0.00883388	0.0223678	0.00724898	0.00898494	0.00787653	0.0303716	0.0101668	0.00888663	0.0197897	0.0195312	0.0298496	0.0429987	0.0437672	0.0183075	0.00938831	0.00676985	0.00704317	0.0090012	0.0164618	0.024809	0.0238433	0.00969202	0.00743192	0.00859938	0.00920962	0.0145953	0.0139836	0.0105339	0.00820678	0.0179423	0.0101806	0.00925494	0.0134333	0.0178578	0.0192623	0.0162391	0.0127804	0.00997488	0.0240395	0.0103568	0.0121206	0.013484
0.0453574	0.0410223	0.0196664	0.0068098	0.00956353	0.0176877	0.0242773	0.0194935	0.0102118	0.00797802	0.00801339	0.0128302	0.0109346	0.0093178	0.0207494	0.0108379	0.00946924	0.0133561	0.0170841	0.0169471	0.0130639	0.010467	0.00892205	0.0222283	0.00727355	0.00905132	0.00791333	0.030494	0.0102535	0.00891984	0.019943	0.0196237	0.0296491	0.0427534	0.0435407	0.018315	0.00934445	0.00681917	0.00707021	0.00893864	0.0163252	0.0245929	0.0234322	0.00956641	0.00743027	0.00865032	0.00924918	0.0146332	0.014026	0.010573	0.00819823	0.0174649	0.0100904	0.00931744	0.0134932	0.0179109	0.0193712	0.0163369	0.012896	0.0100261	0.0239228	0.0104225	0.0122375	0.0136417
0.0439247	0.0395434	0.0195733	0.00713975	0.00989096	0.0176711	0.0239024	0.0192113	0.0105572	0.00830183	0.0082553	0.0129538	0.0111202	0.00964622	0.0202334	0.0110572	0.00971002	0.0134633	0.0171593	0.0170426	0.0131984	0.010673	0.00924461	0.0220018	0.00764045	0.00933735	0.00827037	0.0298696	0.0104076	0.00920457	0.0200219	0.0196736	0.0291177	0.0417173	0.0426724	0.0182858	0.00973541	0.00710873	0.00735606	0.00923024	0.0162984	0.0242171	0.0229061	0.00993515	0.00776311	0.0088795	0.00944354	0.0147227	0.0141193	0.0107743	0.00857932	0.016848	0.010395	0.00958675	0.0136042	0.0179569	0.0194304	0.0164173	0.0130794	0.0103062	0.0233188	0.0105814	0.0123033	0.0134095
0.04429	0.0395713	0.0194612	0.00712167	0.00982424	0.0173452	0.0236315	0.0191568	0.0105029	0.00831034	0.00828404	0.0129825	0.0111431	0.00962789	0.0203203	0.0110391	0.0096982	0.0134693	0.0171482	0.0169812	0.0131739	0.0106633	0.0092033	0.022015	0.00762979	0.00933012	0.00824511	0.0293799	0.0101997	0.00920782	0.0199229	0.0196268	0.029318	0.042128	0.0428477	0.018281	0.00969982	0.00708478	0.00730924	0.00921622	0.0163215	0.0243854	0.0234627	0.00998203	0.00776458	0.00885871	0.00944942	0.0147264	0.0141022	0.0107654	0.00858693	0.0177067	0.0105689	0.00956806	0.0135732	0.0179286	0.0193617	0.0163718	0.0130523	0.0103458	0.0232953	0.010398	0.0121448	0.0128878
0.0453002	0.0408793	0.0194349	0.00678532	0.00943577	0.0172047	0.0241634	0.0195968	0.010273	0.00807162	0.00808664	0.0128475	0.0109959	0.00941913	0.0207941	0.010902	0.00949405	0.0133397	0.0169882	0.016743	0.0129806	0.0104387	0.00890372	0.0223043	0.00740224	0.00907819	0.00797575	0.0299079	0.0100531	0.00900779	0.0196454	0.0194352	0.029847	0.0428097	0.0436334	0.0181019	0.00944888	0.00679543	0.0070523	0.00899728	0.0163503	0.02488	0.0241116	0.0098683	0.00757842	0.00868971	0.00926277	0.014588	0.0140121	0.0106381	0.00841463	0.0183755	0.0104392	0.00938652	0.0134884	0.01785	0.0191923	0.0162334	0.0128308	0.0100713	0.0238895	0.0102715	0.0119521	0.0130515
0.0460595	0.0417632	0.019498	0.00647082	0.00914031	0.0171761	0.0247604	0.0200989	0.0101426	0.00785558	0.00785358	0.0125827	0.0108127	0.00929158	0.0213383	0.0109279	0.00934142	0.0131148	0.0165967	0.016306	0.0126323	0.0100942	0.00863765	0.0227687	0.00717664	0.00868481	0.00766733	0.0309155	0.00997419	0.00872308	0.0192107	0.0190005	0.0306338	0.0436584	0.0443569	0.0180065	0.0093212	0.00646488	0.00682807	0.00880637	0.016416	0.025288	0.0245833	0.00979615	0.0074006	0.00850245	0.00900298	0.0142722	0.0138572	0.0105488	0.00830741	0.0185577	0.0103095	0.00930511	0.0134733	0.0176882	0.0189477	0.016123	0.0126366	0.00984113	0.0248661	0.0103375	0.0118363	0.01341
0.0467804	0.0424804	0.0195353	0.0065659	0.00903811	0.0167281	0.0253179	0.0208275	0.0101503	0.00782578	0.00773641	0.0119866	0.010508	0.00922933	0.0218934	0.0111586	0.00922119	0.012572	0.0156226	0.0154118	0.0120609	0.00973479	0.00850693	0.0240591	0.00745075	0.00850818	0.00789645	0.0326422	0.0102061	0.00868703	0.0181087	0.0178627	0.0317538	0.0443261	0.0449378	0.0178756	0.00974832	0.00652687	0.00690881	0.00855874	0.0157997	0.0257796	0.0252951	0.00983712	0.00758593	0.00849272	0.00878163	0.0135719	0.0134803	0.0105901	0.00839688	0.0188931	0.010469	0.00934045	0.0132118	0.0169494	0.017954	0.0153696	0.0119979	0.00963872	0.0260649	0.0105392	0.0114335	0.0135781
0.0464552	0.0422826	0.0196839	0.0064108	0.00914516	0.0173578	0.0251592	0.0203691	0.00999058	0.00766736	0.00767635	0.0121207	0.0104187	0.0090538	0.0214686	0.0110331	0.009122	0.0126556	0.0159696	0.0160381	0.0123791	0.00983826	0.00856884	0.0237537	0.00728398	0.00866992	0.00782641	0.0325534	0.0101551	0.0087784	0.0189797	0.0182968	0.031104	0.0440567	0.044632	0.018128	0.00948982	0.00635035	0.00669211	0.00847547	0.0158049	0.0254218	0.0247956	0.00964524	0.00732672	0.00832847	0.00875675	0.0136927	0.0134067	0.0104059	0.00824973	0.0187265	0.0104035	0.00928448	0.0133882	0.0172499	0.0187977	0.0160381	0.0125521	0.00988183	0.0259265	0.0105156	0.0117265	0.0135842
0.0457058	0.0414905	0.0196399	0.00650664	0.00932891	0.0176169	0.0244636	0.0195579	0.0100567	0.00785101	0.00792116	0.0127411	0.0108877	0.00922609	0.0207957	0.0108399	0.00940163	0.0133085	0.0168933	0.0167206	0.0129301	0.0103357	0.00880923	0.0220684	0.00722269	0.00892156	0.00783059	0.0306041	0.0101819	0.00885297	0.0197268	0.0193189	0.0299314	0.0431338	0.0438063	0.0181724	0.00921089	0.00648724	0.00677781	0.00872915	0.0162618	0.0248825	0.0239462	0.0096456	0.00735214	0.008499	0.00906163	0.0143951	0.0138693	0.0105354	0.00830117	0.0183093	0.0103617	0.00937462	0.0135509	0.0178601	0.0193709	0.0164325	0.0130413	0.0101503	0.0245036	0.0105096	0.0121321	0.0136479
0.0446771	0.0400892	0.019373	0.00692614	0.00968485	0.0173316	0.0237988	0.0192404	0.01032	0.00816628	0.00819347	0.0129435	0.0110926	0.00947328	0.0202189	0.0108698	0.00962275	0.0134618	0.0171228	0.0169488	0.0131393	0.0106143	0.00911264	0.0216372	0.00750659	0.0092315	0.00812208	0.0297804	0.0103368	0.00908752	0.0199187	0.0195937	0.0295232	0.0422373	0.0428669	0.0181828	0.00950949	0.00689212	0.00710976	0.0090352	0.016229	0.0244579	0.0237029	0.00986255	0.00764733	0.00876641	0.00934939	0.0146669	0.014062	0.0107168	0.00849794	0.0181972	0.0105188	0.00950729	0.0135759	0.0179405	0.0194085	0.0164141	0.0130691	0.010299	0.023663	0.0105863	0.0122161	0.0136524
0.0430629	0.0384651	0.0194105	0.00730804	0.0101674	0.0174739	0.0233217	0.0188333	0.010697	0.00848707	0.00841775	0.0130815	0.011274	0.00981194	0.0196364	0.0110586	0.00986325	0.0135792	0.0172536	0.0171188	0.0132894	0.0108047	0.00943385	0.0216148	0.00781303	0.00948565	0.00842514	0.0290765	0.0104579	0.00931676	0.0200977	0.0197459	0.0290465	0.0414143	0.0417627	0.0183053	0.00994489	0.00722308	0.00745616	0.00941368	0.0163156	0.0239902	0.0231589	0.0101777	0.00791242	0.00898427	0.00956214	0.0148168	0.014188	0.010866	0.00875059	0.0174877	0.0106985	0.00971249	0.0136708	0.0180206	0.0195108	0.0165043	0.0132306	0.0105255	0.02307	0.0106705	0.0123643	0.0133616
0.0436983	0.0389711	0.0196635	0.00717821	0.0101054	0.0176722	0.0232999	0.0186164	0.0105692	0.00836966	0.00834152	0.0130666	0.0112457	0.00967321	0.0193516	0.010944	0.0098517	0.0136421	0.0173035	0.0172316	0.0133634	0.0108514	0.00941405	0.0207735	0.00770423	0.00943746	0.00836176	0.0296771	0.0106829	0.00923493	0.0202633	0.019794	0.0289408	0.0415547	0.041703	0.018482	0.00972915	0.00707481	0.00730472	0.00929191	0.0164825	0.0237642	0.0224917	0.0100457	0.00774463	0.00886685	0.00947864	0.0147786	0.0141286	0.0107738	0.00859695	0.0173273	0.010604	0.0096556	0.0137116	0.0180847	0.0196873	0.016629	0.0132814	0.0105482	0.0234267	0.0108549	0.0125442	0.0140583
0.0446877	0.0401564	0.0196914	0.00694388	0.009804	0.0177071	0.0237818	0.0189851	0.0102708	0.00813079	0.00820051	0.0129395	0.0110953	0.00936503	0.0199607	0.0108173	0.00966301	0.0135486	0.017144	0.0171993	0.0133233	0.01075	0.00918345	0.0208495	0.00747803	0.00931401	0.0081613	0.0299838	0.0105315	0.00913648	0.0202573	0.019548	0.0291153	0.0421134	0.0425823	0.018417	0.00939891	0.00686364	0.00706982	0.00902336	0.0164521	0.0241601	0.0230256	0.00978114	0.00749776	0.00864585	0.00930474	0.0145259	0.0138567	0.0105927	0.00840252	0.017834	0.0104444	0.00956005	0.01369	0.0179701	0.019742	0.0166863	0.0132854	0.010415	0.023695	0.0107526	0.0125188	0.0139692
0.0453914	0.0412619	0.0198866	0.00671293	0.00958352	0.0179479	0.0242437	0.0191048	0.0100057	0.00786708	0.00805703	0.0127916	0.0108931	0.00908616	0.0202836	0.0107097	0.00948499	0.013414	0.0169141	0.0171157	0.0132394	0.0106158	0.00901797	0.0208492	0.00732612	0.00923134	0.00803151	0.0302485	0.0104426	0.0090933	0.0202292	0.0191536	0.0291299	0.042638	0.0433435	0.0183931	0.00918407	0.0066714	0.00690654	0.00885892	0.0165299	0.024562	0.0232822	0.00959354	0.00727687	0.0084416	0.00914134	0.0141945	0.013507	0.0104039	0.00827518	0.0179062	0.0103506	0.00956028	0.0137208	0.0178015	0.0198647	0.0168788	0.0134351	0.0103889	0.0242074	0.0107371	0.0126244	0.0139567
0.0459019	0.0418656	0.0199053	0.00657298	0.00946596	0.0178805	0.0247867	0.0196989	0.00992075	0.00769189	0.00782655	0.0123604	0.0105055	0.00892314	0.0208052	0.0108139	0.0091886	0.0128854	0.0162581	0.0166164	0.0128013	0.0102014	0.00878942	0.0223059	0.00727473	0.00902258	0.00795236	0.0315339	0.0103883	0.00900231	0.0197216	0.0183922	0.0299619	0.043403	0.0440166	0.0183348	0.00929802	0.00650507	0.00680627	0.00871505	0.0163303	0.0249587	0.0239378	0.00958986	0.00717583	0.00825996	0.00891094	0.0137058	0.0130709	0.0101768	0.00821342	0.0182884	0.0103808	0.00949049	0.0135524	0.0172933	0.0195235	0.0167175	0.0133258	0.0103227	0.0253083	0.0107585	0.0124632	0.0139446
0.0470491	0.0427858	0.0192984	0.00666473	0.00897672	0.0160949	0.0254971	0.0211598	0.0101706	0.00791782	0.00786034	0.0118359	0.0101825	0.00909367	0.0221818	0.0113629	0.00891888	0.0121372	0.0152603	0.0156161	0.0121119	0.00961912	0.00836185	0.0250398	0.00754231	0.0087356	0.0080603	0.034157	0.0103665	0.00904144	0.0183781	0.01711	0.0321559	0.0444909	0.0450379	0.0175792	0.00988878	0.00666881	0.00685223	0.00812873	0.0145356	0.0257481	0.0253712	0.00974327	0.00747988	0.00830553	0.00881779	0.0130434	0.0124478	0.010012	0.00846823	0.0191499	0.0106151	0.0093747	0.0129557	0.0161543	0.0181756	0.0155878	0.0121374	0.00963521	0.0267563	0.0107678	0.0115662	0.0137603
0.0461526	0.0420249	0.0198456	0.00657181	0.0093782	0.0175585	0.0249192	0.019983	0.00995776	0.00771997	0.0078374	0.0123601	0.0105893	0.00903476	0.0211514	0.0109311	0.00921239	0.0129224	0.0161497	0.0164759	0.0126724	0.0100392	0.00859964	0.0228753	0.00724985	0.00891327	0.00795561	0.0327275	0.0103975	0.00897309	0.0195171	0.018011	0.0304184	0.0437367	0.0443176	0.0183846	0.00943911	0.00652598	0.00680753	0.00862714	0.0160694	0.0251254	0.024207	0.0096179	0.00716051	0.00819682	0.00886987	0.0135008	0.0126988	0.00993101	0.00813172	0.0183515	0.010305	0.00932564	0.0132813	0.0168858	0.01928	0.0164174	0.0130001	0.0101746	0.0255776	0.0107422	0.0122722	0.0139131
0.0454689	0.0412646	0.0198826	0.0068024	0.00959636	0.0177832	0.0242681	0.0192151	0.0100188	0.00788039	0.00806146	0.0127396	0.010858	0.00907101	0.0204666	0.0107436	0.00944858	0.0133376	0.0167623	0.0170684	0.0131596	0.0105331	0.00890661	0.0212953	0.0072891	0.00920928	0.00807142	0.0314023	0.010551	0.00911869	0.0201853	0.0188185	0.0292958	0.0429856	0.0435762	0.0185802	0.00928707	0.00676527	0.00697496	0.00885707	0.0164729	0.0245553	0.0231697	0.00957412	0.00721476	0.00838499	0.00914425	0.0140144	0.0131481	0.0101385	0.00813116	0.0177732	0.010251	0.00942058	0.0135262	0.0174664	0.0197852	0.0167611	0.0133158	0.0103437	0.0242672	0.0107764	0.0127061	0.0140592
0.0460444	0.0418451	0.0198488	0.00667378	0.00940652	0.0175011	0.0247283	0.0198577	0.00998433	0.00777452	0.00790888	0.0124263	0.010652	0.00905741	0.0210717	0.0109146	0.0092704	0.01297	0.0162082	0.0165913	0.0127705	0.0101916	0.00867851	0.0225512	0.00725496	0.00902547	0.00801007	0.0327416	0.0104958	0.00904367	0.0196639	0.0180849	0.0302395	0.0436419	0.044219	0.018577	0.00944801	0.00664522	0.00688434	0.00870028	0.0161857	0.0250123	0.0239306	0.0095851	0.00714998	0.00822264	0.00894739	0.0135653	0.0126803	0.00988456	0.00807294	0.0181406	0.010254	0.00928362	0.0132501	0.0168947	0.0193905	0.0164548	0.0129969	0.0101555	0.0251442	0.0107592	0.0124347	0.0140015
'''
''' MAD 2s Euclidean**2
0.0621157	0.051062	0.039929	0.0515737	0.0607918	0.0832511	0.0244014	0.034103	0.0210723	0.104011	0.0761822	0.0477937	0.0336131	0.0935312	0.0292184	0.0329542	0.0183447	0.0640417	0.0277264	0.0442843
0.0622455	0.053405	0.0421511	0.0546744	0.0606922	0.0770468	0.0250077	0.0342157	0.0218023	0.0977492	0.0750626	0.0456506	0.0335919	0.100771	0.0294548	0.0321557	0.018281	0.063911	0.02846	0.0436712
0.0618943	0.0524502	0.0420274	0.055079	0.0601493	0.078504	0.0238065	0.0331123	0.0206179	0.101567	0.0758368	0.0463872	0.0326639	0.10296	0.0287655	0.0319304	0.0174558	0.0637203	0.0278936	0.0431788
0.0624151	0.0522994	0.0421993	0.0558976	0.0604928	0.0748173	0.0247969	0.0340594	0.0216016	0.100893	0.0746893	0.0453068	0.0334011	0.101753	0.0293764	0.0321314	0.0180401	0.064035	0.0282251	0.043569
0.0624728	0.0490458	0.0396601	0.0535422	0.0602764	0.0817903	0.0241335	0.0339057	0.0208017	0.107554	0.0754672	0.0476178	0.0334729	0.0941777	0.0291696	0.0327053	0.0181838	0.0642528	0.0276631	0.0441071
0.0627047	0.0430106	0.0349532	0.0446756	0.0608982	0.0921338	0.0222034	0.033546	0.0187425	0.111611	0.0830832	0.0501076	0.0323821	0.0975482	0.0278622	0.033103	0.016785	0.0640573	0.0259776	0.0446146
0.0617216	0.0442216	0.0360924	0.0459732	0.059566	0.0935951	0.0204369	0.0317099	0.0169352	0.11348	0.0829155	0.0504559	0.0306929	0.104964	0.02711	0.0328031	0.0150362	0.0633014	0.0253954	0.0435934
0.0615526	0.0430956	0.0358415	0.0447881	0.0594599	0.0934586	0.0203141	0.031603	0.0169518	0.114347	0.0824605	0.0508428	0.0305762	0.106718	0.0273152	0.0331741	0.0150617	0.0634521	0.0253487	0.0436383
0.0614306	0.0457439	0.0368135	0.0476517	0.0598894	0.0907726	0.0205858	0.0320116	0.0175356	0.114335	0.0820201	0.0491299	0.0305534	0.103367	0.0275346	0.0328549	0.0152535	0.063592	0.0255803	0.0433445
0.062832	0.0445278	0.0361823	0.0472192	0.0607936	0.086009	0.0228659	0.0345776	0.01945	0.113654	0.0806417	0.0488287	0.0328053	0.0934262	0.0297044	0.0336517	0.017483	0.0643927	0.0265227	0.0444326
0.0617222	0.0413364	0.0351307	0.0428479	0.059615	0.0936491	0.0206037	0.0319453	0.017188	0.114325	0.0828003	0.0510393	0.0308896	0.10734	0.0277144	0.0334266	0.015331	0.0636028	0.0255467	0.0439456
0.0622989	0.0422696	0.034977	0.0444309	0.0603534	0.0934072	0.0208009	0.0319377	0.0174089	0.113796	0.0837103	0.0507244	0.0314502	0.104259	0.0270303	0.0330525	0.0154158	0.0639323	0.0247344	0.0440099
0.0611654	0.0451095	0.0368276	0.0475539	0.0587436	0.0928526	0.0200421	0.0311462	0.0166546	0.112692	0.0819207	0.0508373	0.0305387	0.107158	0.0272418	0.0328466	0.0148959	0.0632831	0.0254254	0.043065
0.0608507	0.0454338	0.0370034	0.0473097	0.0584572	0.0921769	0.0202675	0.0313133	0.0169344	0.111658	0.0813882	0.0508961	0.030338	0.107719	0.0277397	0.0331804	0.0151365	0.0628836	0.0260566	0.0432574
0.0606684	0.0464616	0.0372129	0.0482467	0.0588041	0.0925926	0.0198337	0.0309803	0.0165333	0.112777	0.0816794	0.0504075	0.0297954	0.106937	0.0277145	0.0328521	0.014804	0.0628784	0.0256973	0.043123
0.0619453	0.0439545	0.0355256	0.0454189	0.0601859	0.0928377	0.020636	0.0317734	0.0173944	0.11421	0.082869	0.0504968	0.0301663	0.103273	0.0281502	0.03281	0.0155228	0.0637974	0.0251742	0.0438583
0.0609832	0.0486666	0.0388501	0.0517451	0.0589669	0.0891344	0.0201792	0.0309557	0.0170541	0.109741	0.0813716	0.0501641	0.0302106	0.105144	0.0272968	0.0325183	0.0155313	0.0628958	0.0258017	0.0427891
0.0628265	0.0471025	0.038232	0.0492414	0.0610869	0.0834931	0.0241987	0.0336899	0.020769	0.10664	0.0780143	0.0504489	0.0333132	0.093382	0.0296812	0.0336265	0.0181286	0.0644368	0.0273803	0.044308
0.0627061	0.0501145	0.0403517	0.0525316	0.0607929	0.0772959	0.0244144	0.0336363	0.0209973	0.101749	0.0768354	0.0482326	0.0328634	0.100077	0.0295955	0.0336405	0.0179473	0.0642899	0.0278086	0.0441199
0.0626825	0.0472629	0.038203	0.0493499	0.0608163	0.0843546	0.0237871	0.0335151	0.0203373	0.107507	0.0776992	0.0497156	0.0326667	0.0947305	0.0296478	0.0341588	0.0177892	0.0642607	0.0272735	0.0442424
'''